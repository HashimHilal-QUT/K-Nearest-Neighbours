{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b8675d-9603-46a6-91c9-4a0a1b6fa1f3",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours ‚Äì Practice Exercise: Human Activity Recognition\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook challenges you to build a **multi-class classifier** that can identify different physical activities from smartphone sensor data.\n",
    "\n",
    "### Your Mission\n",
    "Create a k-NN model that can distinguish between different physical activities (cycling, walking, jogging, etc.) using only smartphone sensor readings.\n",
    "\n",
    "**Goal Question:** Can we accurately identify what physical activity a person is doing based solely on their smartphone's motion sensors?\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "**Data Source:** Smartphone sensor data collected during various physical activities\n",
    "\n",
    "This dataset contains real smartphone sensor readings from people performing different physical activities with their phone in their pocket. It's a great example of **time-series classification** and **Internet of Things (IoT)** applications.\n",
    "\n",
    "### Dataset Details:\n",
    "- **Multiple activity types:** Cycling, Walking, Jogging, Swimming, Tennis, etc.\n",
    "- **Sensor readings:** 12 different sensor measurements per timestamp\n",
    "- **Real-world data:** Collected from actual smartphone sensors\n",
    "- **Multi-class problem:** More complex than binary classification!\n",
    "- **Applications:** Fitness tracking, health monitoring, activity recommendation\n",
    "\n",
    "### Available Activity Files:\n",
    "- `Cycling.csv` - Bicycle riding data  \n",
    "- `Walking.csv` - Normal walking data\n",
    "- `Jogging.csv` - Jogging/running data\n",
    "- `Swimming.csv` - Swimming activity data\n",
    "- `Tennis.csv` - Tennis playing data\n",
    "- `Football.csv` - Football/soccer data\n",
    "- `JumpRope.csv` - Jump rope exercise data\n",
    "- `Pushups.csv` - Push-up exercise data\n",
    "- `Sitting.csv` - Sitting/stationary data\n",
    "- Plus more activities...\n",
    "\n",
    "### Sensor Features (12 total):\n",
    "\n",
    "| Sensor Type | Features | Description |\n",
    "|-------------|----------|-------------|\n",
    "| **Accelerometer** | X, Y, Z (m/s¬≤) | Measures acceleration forces |\n",
    "| **Gravity** | X, Y, Z (m/s¬≤) | Gravitational component of acceleration |\n",
    "| **Linear Acceleration** | X, Y, Z (m/s¬≤) | Acceleration minus gravity |\n",
    "| **Gyroscope** | X, Y, Z (rad/s) | Measures rotation rates |\n",
    "\n",
    "**Additional columns:** Timestamp and datetime information\n",
    "\n",
    "## What Makes This Challenging?\n",
    "\n",
    "1. **Multi-class classification:** More than 2 categories to predict\n",
    "2. **Time-series data:** Sensor readings change over time\n",
    "3. **Similar activities:** Some activities might have similar sensor patterns\n",
    "4. **Real-world noise:** Smartphone sensors can be noisy\n",
    "5. **Feature engineering:** You might need to create new features from raw sensor data\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "Through this exercise, you will:\n",
    "- Combine multiple CSV files into a single dataset\n",
    "- Handle time-series sensor data\n",
    "- Visualize multi-dimensional sensor patterns\n",
    "- Build a multi-class k-NN classifier\n",
    "- Analyze confusion matrices for multiple classes\n",
    "- Understand which activities are easily confused\n",
    "\n",
    "## Instructions\n",
    "\n",
    "üîç **Reference Material:** Look at `Glass Classification.ipynb` for coding examples, but note this problem is more complex!\n",
    "\n",
    "üí° **Key Reminders:**\n",
    "- This is **multi-class classification** (more than 2 classes)\n",
    "- You'll need to **combine multiple CSV files** \n",
    "- **Feature scaling** is still crucial for k-NN\n",
    "- **Confusion matrix** will be larger (activities √ó activities)\n",
    "- Consider creating **additional features** from raw sensor data\n",
    "\n",
    "**Ready for the challenge? Let's build an activity recognition system**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9603a80-d384-4db9-ab17-46f905babb6d",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "You'll need Python libraries for handling multiple files, sensor data analysis, and multi-class classification.\n",
    "\n",
    "### Essential Imports:\n",
    "- **File handling:** os, glob (to work with multiple CSV files)\n",
    "- **Data manipulation:** pandas, numpy\n",
    "- **Visualisation:** matplotlib, seaborn\n",
    "- **Machine learning:** scikit-learn modules\n",
    "- **k-NN and evaluation:** KNeighborsClassifier, confusion_matrix, classification_report\n",
    "\n",
    "### Understanding Smartphone Sensors:\n",
    "\n",
    "**Accelerometer:** Measures acceleration forces in 3 dimensions\n",
    "- Detects device orientation and movement\n",
    "- Key for detecting walking, running, cycling patterns\n",
    "\n",
    "**Gyroscope:** Measures rotation rates around 3 axes  \n",
    "- Detects spinning and rotational movements\n",
    "- Useful for activities like tennis, football\n",
    "\n",
    "**Gravity vs Linear Acceleration:** \n",
    "- Gravity: The constant downward force (helps determine orientation)\n",
    "- Linear Acceleration: Movement acceleration minus gravity (actual motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107048c5-e9ea-40f8-87b7-637cc3d59012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all required libraries here\n",
    "# Refer to Glass Classification.ipynb for the exact imports needed\n",
    "\n",
    "# File handling for multiple CSV files\n",
    "# Data manipulation and analysis\n",
    "# Visualisation\n",
    "# Machine learning (KNeighborsClassifier, StandardScaler, etc.)\n",
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65e1ff-63a5-44dd-9f20-ea85932c551d",
   "metadata": {},
   "source": [
    "## Step 2: Load and Combine Multiple Activity Files\n",
    "\n",
    "Your biggest challenge: combine multiple CSV files into a single dataset with activity labels!\n",
    "\n",
    "### Strategy:\n",
    "1. **Find all CSV files** in the Data/ folder (except processed ones)\n",
    "2. **Load each file** and add an 'activity' column\n",
    "3. **Combine all dataframes** into one master dataset\n",
    "4. **Clean the data** and standardize column names\n",
    "\n",
    "### Activity Label Mapping:\n",
    "You'll need to create labels for each activity:\n",
    "- Cycling ‚Üí 0\n",
    "- Walking ‚Üí 1  \n",
    "- Jogging ‚Üí 2\n",
    "- Swimming ‚Üí 3\n",
    "- Tennis ‚Üí 4\n",
    "- Football ‚Üí 5\n",
    "- etc.\n",
    "\n",
    "### Key Challenges:\n",
    "- Different files might have different numbers of samples\n",
    "- Sensor data might be noisy or have outliers\n",
    "- Some files might have slightly different column formats\n",
    "- You need to balance the number of samples per activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313a445-c6e3-4452-b892-3144f616fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load and combine multiple activity CSV files\n",
    "# Find all CSV files in Data/ folder (exclude processed files)\n",
    "# Load each file and add activity labels\n",
    "# Combine all dataframes into one master dataset\n",
    "# Clean column names and display basic info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedcb18-a886-46d0-a773-253a7ea601dd",
   "metadata": {},
   "source": [
    "## Step 3: Visualise Sensor Data Patterns\n",
    "\n",
    "Understanding sensor patterns is crucial for activity recognition! Create visualisations to see how different activities create different sensor signatures.\n",
    "\n",
    "### Recommended Visualisations:\n",
    "\n",
    "1. **Activity Distribution:** Bar chart showing sample counts per activity\n",
    "2. **Sensor Time Series:** Line plots showing how sensors change during different activities\n",
    "3. **Sensor Magnitude:** Calculate and plot the magnitude of acceleration vectors\n",
    "4. **Activity Comparison:** Box plots comparing sensor values across activities  \n",
    "5. **Correlation Analysis:** Heatmap of sensor correlations\n",
    "\n",
    "### Key Questions to Explore:\n",
    "- Which sensors show the biggest differences between activities?\n",
    "- Do similar activities (walking vs jogging) have similar sensor patterns?\n",
    "- Can you see periodic patterns (like steps) in the time series?\n",
    "- Which activities have the most/least sensor variation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373b31b-1afa-4bbb-b38a-1d93b8a6bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create sensor data visualisations\n",
    "# Activity distribution bar chart\n",
    "# Calculate sensor magnitudes (derived features)\n",
    "# Box plots comparing sensor values across activities\n",
    "# Time series plots for sample activities\n",
    "# Correlation heatmap of sensor features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e455fd-bf1c-4984-b9db-463992ebc441",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering and Data Preprocessing\n",
    "\n",
    "Sensor data often benefits from feature engineering! You might want to create new features that capture important patterns.\n",
    "\n",
    "### Feature Engineering Options:\n",
    "\n",
    "1. **Magnitude Features:** ‚àö(x¬≤ + y¬≤ + z¬≤) for each sensor type\n",
    "2. **Statistical Features:** Mean, std, min, max over time windows\n",
    "3. **Frequency Features:** Extract frequency domain features using FFT\n",
    "4. **Ratio Features:** Ratios between different sensor magnitudes\n",
    "\n",
    "### Standard Preprocessing Steps:\n",
    "\n",
    "1. **Select Features:** Choose which sensor readings and derived features to use\n",
    "2. **Handle Missing Values:** Check for and handle any NaN values\n",
    "3. **Feature Scaling:** Standardize all features (CRUCIAL for k-NN!)\n",
    "4. **Train/Test Split:** Split data while maintaining activity balance\n",
    "\n",
    "### Time Series Considerations:\n",
    "\n",
    "- **Option 1:** Use individual sensor readings as features (simpler)\n",
    "- **Option 2:** Create sliding windows and extract features from each window (more advanced)\n",
    "- **Option 3:** Sample data points to reduce dataset size while maintaining patterns\n",
    "\n",
    "For this exercise, we'll start with Option 1 (individual readings) but you can experiment with others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ce2da-b55e-438e-9197-a3fce0a4ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature Engineering and Preprocessing Steps\n",
    "# Create magnitude features from sensor readings\n",
    "# Select features for k-NN (individual readings vs magnitude features)\n",
    "# Prepare features (X) and target (y)\n",
    "# Handle any missing values\n",
    "# Optional: Sample data to reduce size if dataset is very large\n",
    "# Scale features for k-NN\n",
    "# Train/test split with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac550fc-12da-42a4-99fc-42a05a906e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hyperparameter Tuning for Multi-Class k-NN\n",
    "# Test different k values using cross-validation\n",
    "# Find best k value for multi-class classification\n",
    "# Plot k vs accuracy\n",
    "# Note optimal k value for final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5fb73-5394-4515-99a3-e2229ffe48db",
   "metadata": {},
   "source": [
    "## Step 5: Train Final Model and Evaluate Multi-Class Performance\n",
    "\n",
    "Multi-class classification evaluation is more complex than binary classification. You'll need to analyse performance for each activity class.\n",
    "\n",
    "### Multi-Class Evaluation Metrics:\n",
    "\n",
    "- **Overall Accuracy:** Percentage of correct predictions across all activities\n",
    "- **Per-Class Precision/Recall:** How well does the model perform for each specific activity?\n",
    "- **Macro Average:** Average metrics across all classes (treats each activity equally)  \n",
    "- **Weighted Average:** Average metrics weighted by class frequency\n",
    "- **Confusion Matrix:** Shows which activities are confused with each other\n",
    "\n",
    "### Important Questions:\n",
    "- Which activities are easiest/hardest to classify?\n",
    "- Are similar activities (walking/jogging) often confused?\n",
    "- Does the model have bias toward more frequent activities?\n",
    "- How does performance compare to random guessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b50119-24a6-4e82-9e38-930080652dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train final k-NN model and evaluate multi-class performance\n",
    "# Train final model with best k\n",
    "# Make predictions on test set\n",
    "# Print detailed classification report with activity names\n",
    "# Calculate overall accuracy\n",
    "# Compare to random baseline accuracy\n",
    "# Show per-class accuracy for each activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf892a7-7587-4802-bbce-de9beb4b94a8",
   "metadata": {},
   "source": [
    "## Step 6: Multi-Class Confusion Matrix Analysis\n",
    "\n",
    "The confusion matrix for multi-class problems is much more informative than binary classification. It shows exactly which activities are confused with each other.\n",
    "\n",
    "### How to Read a Multi-Class Confusion Matrix:\n",
    "\n",
    "- **Diagonal elements:** Correct predictions for each activity\n",
    "- **Off-diagonal elements:** Confusion between different activities\n",
    "- **Row sums:** Total actual samples for each activity  \n",
    "- **Column sums:** Total predicted samples for each activity\n",
    "\n",
    "### Key Analysis Questions:\n",
    "\n",
    "- **Which activities are never confused?** Look for activities with high diagonal values and low off-diagonal values\n",
    "- **Which activities are most similar?** Activities that are frequently confused might have similar sensor patterns\n",
    "- **Is there systematic bias?** Does the model favour predicting certain activities over others?\n",
    "- **What are the most common errors?** Which activity pairs are most frequently confused?\n",
    "\n",
    "This analysis can help you understand the physical similarities between activities and guide future feature engineering!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a47dbb-2cf8-4eeb-bd49-5941418ecc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and analyze the multi-class confusion matrix\n",
    "# Compute confusion matrix for all activities\n",
    "# Create large heatmap visualization with activity names\n",
    "# Analyze confusion patterns between activities\n",
    "# Find most confused activity pairs\n",
    "# Calculate and display detailed per-activity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50y1k6ock54",
   "metadata": {},
   "source": [
    "## Reflection and Advanced Challenges\n",
    "\n",
    "### Questions to Consider:\n",
    "1. **How did your multi-class k-NN perform?** Compare accuracy to random guessing and note which activities were hardest to classify.\n",
    "2. **What patterns did you discover?** Which activities are most easily confused and why might that be?\n",
    "3. **How did this compare to the other exercises?** Was multi-class harder than binary classification?\n",
    "4. **What role did feature engineering play?** Did magnitude features help? What other features might work?\n",
    "\n",
    "### Key Learnings from Activity Recognition:\n",
    "- **Sensor fusion is powerful** - combining multiple sensor types improves performance\n",
    "- **Similar activities are harder to distinguish** - walking vs jogging might be challenging\n",
    "- **Feature engineering matters** - raw sensor readings vs derived features\n",
    "- **Class imbalance affects performance** - activities with fewer samples are harder to classify\n",
    "- **Real-world applications** - this is how fitness trackers and smartphones work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
